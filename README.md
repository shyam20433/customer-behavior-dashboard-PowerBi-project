ğŸŒŸ Customer Behavior Analysis â€“ End-to-End Data Pipeline

An end-to-end retail analytics project to understand customer behavior, shopping patterns, and purchase drivers using:

Python (Pandas)

PostgreSQL (ETL + SQL Analytics)

Power BI (Dashboard)

Mermaid (Pipeline Flowchart)

ğŸ“Œ Dataset

Source: Kaggle â€“ Consumer Behavior and Shopping Habits

Rows: 3,900

Columns: 19

Format: CSV

Description: Contains customer demographics, purchases, ratings, discounts, shipping method, and shopping habits.

ğŸš€ Project Workflow
1. Data Cleaning (Python Pandas)

The dataset was cleaned and transformed using Pandas:

âœ” Steps Performed

Imported dataset into Jupyter Notebook

Checked missing values

Cleaned review_rating

Filled missing values using category-wise median

Snake Casing

Converted all column names â†’ lowercase

Replaced spaces with _

Age Segmentation
Categorized age into:

Young

Adult

Middle aged

Senior

Converted frequency_of_purchases to numerical groups

Removed promo_code

Because promo_code_used and discount_applied were identical

Exported cleaned dataset â†’ final_customer_behavior.csv

ğŸ—„ï¸ 2. PostgreSQL ETL Pipeline

We used a two-table ETL approach to ensure clean and validated data:

âœ” Staging Table: customer_stage (all TEXT)

Purpose: Safe CSV import without errors.

CREATE TABLE public.customer_stage (
    customer_id TEXT,
    age TEXT,
    gender TEXT,
    item_purchased TEXT,
    category TEXT,
    purchase_amount TEXT,
    location TEXT,
    size TEXT,
    color TEXT,
    season TEXT,
    review_rating TEXT,
    subscription_status TEXT,
    shipping_type TEXT,
    discount_applied TEXT,
    previous_purchases TEXT,
    payment_method TEXT,
    frequency_of_purchases TEXT,
    age_group TEXT,
    purchase_frequency_days TEXT
);

âœ” Final Table: customer (typed + constraints)

Clean, validated dataset used for analysis.

INSERT INTO public.customer (
    customer_id, age, gender, item_purchased, category,
    purchase_amount, location, size, color, season,
    review_rating, subscription_status, shipping_type,
    discount_applied, previous_purchases, payment_method,
    frequency_of_purchases, age_group, purchase_frequency_days
)
SELECT
    customer_id::BIGINT,
    age::INT,
    gender,
    item_purchased,
    category,
    purchase_amount::BIGINT,
    location,
    size,
    color,
    season,
    review_rating::NUMERIC(3,1),
    subscription_status,
    shipping_type,
    CASE
        WHEN discount_applied ILIKE 'yes' THEN TRUE
        WHEN discount_applied ILIKE 'no'  THEN FALSE
        ELSE NULL
    END,
    previous_purchases::INT,
    payment_method,
    frequency_of_purchases,
    age_group,
    NULLIF(purchase_frequency_days, '')::NUMERIC(10,1)::INT
FROM public.customer_stage;

ğŸ§  3. SQL Analytics (9 Insights)
1ï¸âƒ£ Total revenue by gender
2ï¸âƒ£ High-spending discount users
3ï¸âƒ£ Top 5 products by rating
4ï¸âƒ£ Avg spend by shipping type
5ï¸âƒ£ Subscriber vs Non-subscriber spend
6ï¸âƒ£ Highest discount-used products
7ï¸âƒ£ Customer segmentation (New/Returning/Loyal)
8ï¸âƒ£ Subscription likelihood among repeat buyers
9ï¸âƒ£ Revenue by age group

(Add SQL queries in a folder like /sql/queries.sql for GitHub)

ğŸ“Š 4. Power BI Dashboard

Created measures:

Customer Count = COUNT(customer[customer_id])
Avg Rating = AVERAGE(customer[review_rating])
Avg Purchase = AVERAGE(customer[purchase_amount])


Dashboard Visualizations:

Revenue by Age Group

Revenue by Gender

Discount Usage Analysis

Shipping Type Insights

Top Products by Rating

Customer Segmentation Distribution

Purchase Frequency Analysis

ğŸ—ï¸ Mermaid Flowchart (End-to-End Pipeline)
flowchart TD

A[Kaggle Dataset (CSV)] --> B[Python Pandas Cleaning]
B --> C[Export Cleaned CSV]

C --> D[PostgreSQL - Staging Table (customer_stage)]
D --> E[Data Type Conversion + CAST]
E --> F[Final Table: customer]

F --> G[SQL Analytics (9 Insights)]
G --> H[Power BI Dashboard]

style A fill:#f3f3f3,stroke:#333,stroke-width:1px
style B fill:#ffe8cc,stroke:#d18800
style C fill:#e7f5ff,stroke:#1c7ed6
style D fill:#f8d7da,stroke:#b71c1c
style E fill:#d1e7dd,stroke:#0f5132
style F fill:#dbe4ff,stroke:#364fc7
style G fill:#faf0e6,stroke:#8b4513
style H fill:#e2e3e5,stroke:#333

ğŸ“ Project Structure
customer-behavior-analysis/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw_dataset.csv
â”‚   â”œâ”€â”€ final_customer_behavior.csv
â”‚
â”œâ”€â”€ sql/
â”‚   â”œâ”€â”€ staging_table.sql
â”‚   â”œâ”€â”€ final_table_insert.sql
â”‚   â”œâ”€â”€ analysis_queries.sql
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ cleaning.ipynb
â”‚
â”œâ”€â”€ dashboard/
â”‚   â”œâ”€â”€ powerbi_dashboard.pbix
â”‚
â””â”€â”€ README.md

âš™ï¸ How to Run This Project
1. Clone Repository
git clone https://github.com/your-username/customer-behavior-analysis.git
cd customer-behavior-analysis

2. Install Python Dependencies
pip install pandas numpy

3. Run Notebook
jupyter notebook notebooks/cleaning.ipynb

4. Import into PostgreSQL

Use pgAdmin â†’ Import â†’ staging table â†’ run insertion query.

5. Open Power BI

Connect to PostgreSQL

Load customer table

Add measures

Build visuals

ğŸ–¼ï¸ Screenshots (Add Images Here for GitHub)
âœ” Data Cleaning (Jupyter)
âœ” PostgreSQL Tables
âœ” SQL Query Outputs
âœ” Power BI Dashboard
â­ Conclusion

This project demonstrates a complete data pipeline:

Python-based cleaning

DB-level ETL architecture

Analytical SQL queries

Business insights

Power BI dashboard

A fully functional end-to-end analytics project suitable for portfolio and resume.